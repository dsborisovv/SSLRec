optimizer:
  name: adam
  lr: 1.0e-3
  weight_decay: 0

train:
  epoch: 3
  batch_size: 1024
  save_model: true
  log_loss: false
  test_step: 1
  reproducible: true
  seed: 2023

test:
  metrics: [recall, ndcg]
  k: [5, 10, 20]
  batch_size: 1024

data:
  type: sequential
  name: ml-20m
  seq_aug: true

model:
  name: dcrec_seq
  dropout_rate: 0.1
  graph_dropout_prob: 0.3
  n_layers: 2
  embedding_size: 64
  n_heads: 2
  max_seq_len: 50
  cl_lambda: 1.0e-4
  cl_temp: 0.8
  weight_mean: 0.4
  sim_group_k: 4
  kl_weight: 1.0e-2

tune:
  enable: false
  hyperparameters: [cl_lambda, weight_mean]
  cl_lambda: [1.0e-4, 1.0e-3, 1.0e-2]
  weight_mean: [0.4, 0.5, 0.6]
